
# ğŸ“¦ CellphoneS Product Crawler (BeautifulSoup + CSV Export)

A Python crawler for extracting **product and category data** from [CellphoneS.com.vn](https://cellphones.com.vn/).  
It uses `requests` and `BeautifulSoup` to collect structured product information and export clean **CSV files** ready for import into **Supabase** or any other backend system.

---

## ğŸš€ Key Features

âœ… Automatically discovers and parses all `product-sitemap.xml` and `.xml.gz` files  
âœ… Recursively follows sitemap indexes â†’ urlsets  
âœ… Extracts **name, price, description, image, availability, and breadcrumb (category)**  
âœ… Builds a hierarchical **category tree** dynamically from breadcrumbs  
âœ… Generates **deterministic UUID v5** IDs for both categories and products (no duplicates, no slug needed)  
âœ… Exports two clean CSV files:
- `categories.csv` â€” id, name, parent_id, is_popular  
- `products.csv` â€” id, name, price, description, image_url, is_available, category_id  

---

## ğŸ§± Repository Structure
```

ğŸ“‚ Python-CellphoneZ/
â”œâ”€â”€ CellphoneS_Crawl.py     # Main crawler script
â”œâ”€â”€ export/                 # Output directory (auto-created)
â””â”€â”€ README.md               # This file

````

---

## ğŸ§© Requirements

- Python **>= 3.10**
- Install dependencies:
```bash
pip install requests beautifulsoup4 lxml
````

---

## âš™ï¸ How to Use

### 1ï¸âƒ£ Basic run

```bash
python CellphoneS_Crawl.py --limit 500 --outdir ./export
```

### 2ï¸âƒ£ Optional arguments

| Flag       | Description                                  | Default           |
| ---------- | -------------------------------------------- | ----------------- |
| `--limit`  | Max number of products to crawl (None = all) | 200               |
| `--outdir` | Output folder for CSV files                  | `.`               |
| `--delay`  | Delay between requests (seconds)             | 0.35              |
| `--ua`     | Custom User-Agent string                     | default Chrome UA |

Example:

```bash
python CellphoneS_Crawl.py --limit 1000 --delay 0.6 --ua "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
```

Expected output:

```
âœ… Done. Wrote ./export/categories.csv & ./export/products.csv
Categories: 80 | Products parsed: 500
```

---

## ğŸ“„ Output File Details

### ğŸ—‚ categories.csv

| Column     | Type      | Description                                          |
| ---------- | --------- | ---------------------------------------------------- |
| id         | uuid      | UUID v5 generated from category path                 |
| name       | text      | Category name (e.g. â€œSmartphonesâ€, â€œSamsung Galaxyâ€) |
| parent_id  | uuid/null | Parent category UUID (or null for root)              |
| is_popular | boolean   | true if part of the top navigation                   |

### ğŸ“¦ products.csv

| Column       | Type             | Description                                         |
| ------------ | ---------------- | --------------------------------------------------- |
| id           | uuid             | UUID v5 generated from product URL                  |
| name         | text             | Product name (H1 title)                             |
| price        | double precision | Price (converted from â€œ27.280.000Ä‘â€ â†’ `27280000.0`) |
| description  | text             | Concatenated â€œKey featuresâ€ section                 |
| image_url    | text             | Product thumbnail or `og:image`                     |
| is_available | boolean          | true if â€œMUA NGAYâ€ or â€œAdd to cartâ€ visible         |
| category_id  | uuid             | Foreign key to matching category                    |

---

## ğŸ§  UUID v5 Strategy

To ensure stable, repeatable IDs across multiple runs:

```
category.id = uuid5(NAMESPACE_URL, "cellphones:/cat/" + category_path)
product.id  = uuid5(NAMESPACE_URL, "cellphones:/prod/" + product_url)
```

â†’ Guarantees **no duplicates** and **no ID drift** even if crawled at different times.

---

## ğŸ” How It Works

1. **Discover sitemaps** (`product-sitemap*.xml` / `.xml.gz`)
   â†’ Recursively traverse sitemap indexes to get all product URLs
2. **Iterate through product pages** and extract:

   * H1 name
   * Price block (â€œGiÃ¡ sáº£n pháº©mâ€)
   * Description (â€œTÃ­nh nÄƒng ná»•i báº­tâ€)
   * Image (gallery or Open Graph)
   * Availability (based on button text)
   * Breadcrumbs for category mapping
3. **Generate UUIDs** and build a category tree in memory
4. **Export as CSV** with proper relational foreign keys.

---

## ğŸ§° Technical Notes

| Situation                                 | Behavior                           |
| ----------------------------------------- | ---------------------------------- |
| Sitemap uses `.xml.gz`                    | Script auto-decompresses           |
| Nested sitemap indexes                    | Fully recursive                    |
| Breadcrumb noise (â€œTrang chá»§â€, â€œTin tá»©câ€) | Automatically filtered             |
| Vietnamese currency                       | Regex-normalized to numeric format |
| Anti-bot defenses                         | Add `--ua` or increase `--delay`   |
| Missing output folder                     | Automatically created              |

---

## ğŸ§¾ Sample Output (simplified)

**categories.csv**

```
id,name,parent_id,is_popular
3b8...,"Smartphones",,true
2a5...,"Samsung Galaxy",3b8...,false
```

**products.csv**

```
id,name,price,description,image_url,is_available,category_id
7d1...,"Samsung Galaxy S25 Ultra",27280000,"â€¢ Premium titanium frame â€¢ 200MP camera",https://cdn.cellphones.com.vn/media/catalog/product/s25ultra.jpg,true,2a5...
```

---

## ğŸ§ª Quick Test

```bash
python CellphoneS_Crawl.py --limit 10 --outdir ./export --delay 0.5
```

---

## ğŸ§¤ License

**MIT License** â€” free to use, modify, and distribute for learning, research, or personal projects.

---

## ğŸ‘¨â€ğŸ’» Author

**TheKhiem7**

> Flutter + Supabase + Python stack enthusiast ğŸğŸ“±

---

### â­ If you find this useful, give the repo a Star!